\documentclass[]{article}
\usepackage{assignment}
\usepackage{codex}
\usepackage{titlesec}
\titleformat{\section}
  {\Large\scshape}{Session \thesection}{1em}{}
\title{H0E76A: Model Predictive Control\\\large--- Homework assignments ---}
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\author{Muhammad Saad Bin Amin (r1016396)}  % TODO: fill in your name
%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\acyear}{2025-2026}
\newcommand{\assignmentweight}{7/20}

\newcommand{\toledo}{Toledo}

\begin{document}
\maketitle



The assignments below are homework assignments related to the exercise sessions that are organized throughout the 
semester.
The assignments count for \assignmentweight{} of the total marks on this course, and are graded based on the following deliverables
\begin{deliverables}
\begin{itemize}
	\item A report containing the answers to the questions and any numerical values or plots that are asked in the assignments. 
	You can write your solutions directly in this \texttt{tex}-file. Make sure to fill in your name above. 
	\item A single zip-archive containing all the code to generate the plots included in your report. 
	Make sure to add a readme file describing which script(s) to run (and the working directory from which to do so) to reproduce your results.
	It is recommended that you have at least one separate script per session.
\end{itemize}
\end{deliverables}
Most of the assignments build upon the solutions obtained from the sessions.
Solutions for the exercise sessions will be made available on \toledo{} shortly after each session. 
Before submitting your final report, make sure that you verify your solutions from the sessions if you reuse them here. 

\section{LQR and Dynamic programming}
\begin{assignment} Compare the finite horizon controllers $K_{N}$ you computed during the session with the infinite horizon LQR controller.
\begin{itemize} 
	\item Implement the infinite horizon LQR controller $u = K_{\infty} x$ (with initial state $x_0 = (10,10)$).\footnote{Use \texttt{solve\_discrete\_are} from \texttt{scipy.linalg}.} Write the obtained value for $K_\infty$.
	\textbf{Remark.} Report your answers with at least four decimal places.
	\item Plot the simulated closed-loop trajectory of this controller with the trajectories of the finite-horizon controller. What happens as 
	you increase $N$?
	\item Explain this observation based on the recursion relation used earlier and 
	the discrete-time algebraic Riccati equation (DARE).
\end{itemize}
\end{assignment}
\begin{solutionbox}
\begin{itemize}
	\item The $K_\infty$ controller is implemented by solving the DARE using \texttt{scipy.linalg.solve\_discrete\_are} for $P$. Then $K_\infty$ is calculated by 
	$$
		K_\infty = -(R+B^TPB)^{-1}B^TPA
	$$
	The value for $K_\infty$ is $[1.2864, 2.3126]$

	\begin{center} 
		\includegraphics[width=0.6\textwidth]{../figs/1.1_state_traj.pdf}
		\captionsetup{hypcap=false}
		\captionof{figure}{State trajectories for different controllers starting at $(10,10)$}
		\label{fig:1.1-state-traj}
	\end{center}
	
	\item Figure~\ref{fig:1.1-state-traj} shows that increasing the horizon $N$ brings the trajectories closer and closer to the infinite horizon controller's trajectory. For $N<5$ the controllers are unstable as can be seen. 
	\item The recursion relation used earlier is 
	$$
		P_{+} = Q + A^T(P-PB(R+B^TPB)^{-1}B^TP)A
	$$
	As $N$ is increased, the recursion converges to the DARE given by 
	$$
		P = Q + A^T(P-PB(R+B^TPB)^{-1}B^TP)A
	$$
	This behavior is because by increasing $N$ the finite horizon cost can approximate the infinite horizon cost. For a stabilizing control sequence, the stage costs decrease to zero exponentially so the Riccati recursion reaches a steady state. Thus adding more terms does not change the cost significantly and convergence occurs.
\end{itemize}
\end{solutionbox}

\begin{assignment}
	Numerically compare the quality of the finite-horizon LQR controller to the infinite horizon controller. 
	For the same fixed $x_0$ as before and for $N$ ranging from 1 to 10\footnote{\textbf{Hint:} manually set the $y$-limit of the plot to $[0, 2000]$. Otherwise, the costs of unstable controllers will dominate the figure.}: 
\begin{itemize}
	\item Plot $V_{N} = x_0^\top P_N x_0$ versus $N$
	\item Plot $V_{\infty} = x_0^\top P_{\infty} x_0$ on the same axis (this is just a horizontal line).
	\item Approximate the infinite horizon cost for the finite-horizon controller using a long state and input trajectory:
		\begin{align} \nonumber
			\hat{V}_{N} = \sum_{k=0}^\infty(x_k^\top Q x_k + x_k^\top K^\top R K x_k) \approx \sum_{k=0}^{100}(x_k^\top Q x_k + x_k^\top K^\top R K x_k). 
		\end{align}
	and add a plot of $\hat{V}_N$ vs. $N$ on the same figure.
	\item Describe what you observe: Do you observe convergence? Which quantities observe to which and in what direction? \textbf{Briefly} explain these observations.
\end{itemize}
\end{assignment}
\begin{solutionbox}
\begin{center}
	\includegraphics[width=0.6\textwidth]{../figs/1.2_cost_compare.pdf}
	\captionsetup{hypcap=false}
	\captionof{figure}{Optimal cost and Infinite Horizon cost for different horizons for $x_0=(10,10)$}
	\label{fig:1.2-costs}
\end{center}
It can be seen that the Optimal cost converges to the infinite horizon cost from below as $N$ increases whereas the total infinite horizon cost converges from above. This is because increasing $N$ adds more terms of stage cost $l(x,u) \ge 0$ to $V_N$ which for a stable system go to zero exponentially. So as $N\to \infty$, $V_N \to V_\infty$ from below. For the approximated infinite horizon cost $\hat{V}_N$, small $N$ do not result in stabilizing sequence so stage cost grows exponentially. Increasing $N$ makes the system stable making the stage costs smaller. Therefore as $N\to \infty$, $\hat{V}_N \to V_\infty$ from above.
\end{solutionbox}

\newpage
\section{Linear MPC and convex optimization}
\textbf{See the session 2 sheet for the set-up.}

The goal of this assignment is to look more closely at what goes wrong in the 
final exercise of the session, and to gain some intuition about ways to fix it.
In essence, the problem that occurs is a symptom of the myopic nature of MPC,
that is, it can only take into account what happens in the very near future.
To rectify this, we have to provide it with information about the long-term
behavior of the system under the applied controls.

\textbf{Remark.} The assignments in this session should be performed in discrete time.

\begin{assignment}
	Consider the vehicle at a fixed position and velocity $(p_0, v_0)$.
	Suppose we apply the maximum brake, i.e., $u_t = u_{\min}$ for $t = 0, \dots, T$.
	Write an expression of $T$ as a function of $v_0$, such the vehicle can come to standstill in $T$ steps.
\end{assignment}
\begin{solutionbox}
Based on the provided model 
$$
x_{k+1} = \begin{bmatrix} 1 & T_{\mathrm{s}} \\ 0 & 1 \end{bmatrix} x_k + \begin{bmatrix} 0 \\ T_{\mathrm{s}} \end{bmatrix} u_k
$$
with $x=(p,v)$, the velocity equation can be written as 
\begin{align}
	v_1 &= v_0 + u_{\mathrm{min}}T_{\mathrm{s}} \notag \\
	v_2 &= v_1 + u_{\mathrm{min}}T_{\mathrm{s}} = v_0 + 2u_{\mathrm{min}}T_{\mathrm{s}} \notag \\
	\vdots \notag \\ 
	v_T &= v_0 + Tu_{\mathrm{min}}T_{\mathrm{s}} \notag \\ 
	\Rightarrow T &= -\frac{v_0}{u_{\mathrm{min}T_{\mathrm{s}}}}
\end{align}
\end{solutionbox}

\begin{assignment}
	For a given $T$, compute the total braking distance, i.e., the distance traveled during the 
	deceleration: $p_T - p_0$. 
\end{assignment}
\begin{solutionbox}
Proceeding similarly as before, this time with $p$
\begin{align}
	p_1 &= p_0 + v_0Ts \notag \\ 
	p_2 &= p_1 + v_1Ts = p_0 + 2v_0T_{\mathrm{s}} + u_{\mathrm{min}}T_{\mathrm{s}}^2 \notag \\ 
	\vdots \notag \\ 
	p_T &= p_0 + Tv_0T_{\mathrm{s}} + \sum_{k=0}^{T-1}(k)u_{\mathrm{min}}T_{\mathrm{s}}^2 \notag \\
	\Rightarrow p_T-p_0 &= Tv_0T_{\mathrm{s}} + \frac{T(T-1)}{2}u_{\mathrm{min}}T_{\mathrm{s}}^2 
\end{align}
\end{solutionbox}


\begin{assignment}\label{ex:sess2-constraint}
   Use the result of the previous exercises to formulate a constraint on a state $x = (p, v)$ that 
   will guarantee that there will always exist a control input that will keep future states 
   in the set $S = \{x \mid p \leq p_{\max}\}$.
\end{assignment}

\begin{solutionbox}
Minimum braking distance happens when maximum brakes are applied ($u_k=u_{\mathrm{min}}$). Therefore under maximum braking, as calculated in the previous exercise,
\begin{align}
	p_T &= p_0 + Tv_0T_{\mathrm{s}} + \frac{T(T-1)}{2}u_{\mathrm{min}}T_{\mathrm{s}}^2 \notag \\
	T &= -\frac{v_0}{u_{\mathrm{min}T_{\mathrm{s}}}} \notag \\ 
	\frac{T(T-1)}{2} &= \frac{v_0^2 + u_{\mathrm{min}}v_0T_{\mathrm{s}}}{2u_{\mathrm{min}}^2T_{\mathrm{s}}^2} \notag \\ 
	\Rightarrow p_T &= p_0 - \frac{v_0^2}{2u_{\mathrm{min}}}+ \frac{1}{2}v_0T_{\mathrm{s}} \label{eq:pt_v0_p0}
\end{align}

Thus equation~\ref{eq:pt_v0_p0} relates the maximum braking distance with initial state. Combining it with the set constraint gives us the maximal control invariant set $S_\infty$
\begin{align}
	S_\infty = \{x \mid p - \frac{v^2}{2u_{\mathrm{min}}}+ \frac{1}{2}vT_{\mathrm{s}} \le p_{\mathrm{max}}\}
\end{align}
\end{solutionbox}

\begin{assignment} \label{ex:extra-1}
	Write a function that takes the horizon $N$ as an input and that 
	for all initial states $[-10, 0] \leq x_0 \leq [1, 25]$ (sampled in a grid), checks whether your MPC controller is feasible at this initial state.
	Set $u_{\min} = -5$.
	Leave the other settings at the same values as the ones in the session.
	For all $N \in \{2, 5, 10\}$, make a plot showing the set of states that are feasible (this can be a simple scatter plot), 
	and draw the boundary of the constraint you derived in \cref{ex:sess2-constraint}. 
	\textbf{Remark.} You only have to check the initial feasibility of the MPC problem, not recursive feasibility.
\end{assignment}
\begin{solutionbox}
\begin{center}
	\includegraphics[width=0.6\textwidth]{../figs/2.4_feasibility.pdf}
	\captionsetup{hypcap=false}
	\captionof{figure}{The feasible region for MPC controllers with different $N$ along with the constraint boundary for $S_\infty$}
	\label{fig:2.4}
\end{center}
Figure~\ref{fig:2.4} shows the initial feasibility for MPC controller with different prediction horizons along with the constraint boundary for calculated $S_\infty$. As $N$ increases the feasibility converges to the calculated region. Since this is only initial feasibility, short horizons cannot look ahead in the future far enough to detect infeasibility. Therefore their feasibility region is larger.
\end{solutionbox}

\newpage
\section{MPC theory: terminal ingredients}
During the sessions, we have computed polyhedral invariant sets to use 
for the terminal ingredients in our MPC controller. 
Alternatively, we can use ellipsoidal sets. 
The goal of this assignment is to compute such sets in a few different ways 
and compare them with the invariant sets we've computed during 
the session.

\begin{assignment} \label{sess3:assign-lqr}
	Let $K, P$ denote the optimal, infinite-horizon LQR gain and the solution of 
	the discrete-time Riccati equation, respectively. As shown in the lectures, 
	any level set
	\[ 
		\lev_{\alpha} V_{\infty} = \{x \mid V_{\infty}(x) = x^\top P x \leq \alpha\}
	\]
	is a positive invariant set for the system under the policy $u = Kx$. However, 
	not all states $x \in \lev_{\alpha} V_{\infty}$ necessarily satisfy the state and input constraints. 

	Write down the expression for the largest value of $\alpha$ 
	such that
	\[ 
	\begin{cases}
		x \in X \\
		Kx \in U  
	\end{cases} \quad \forall x \in \lev_{\alpha} V_{\infty},
	\]
	where $X = \{x \in \R^n \mid H_x x \leq h_x\}$ and $U = \{u \in \R^m \mid H_u u \leq h_u \}$ are 
	the (polyhedral) sets of feasible states and inputs, respectively.

	\textbf{Hint.} The notion of a support function might be of use.
\end{assignment}



\begin{assignment}
	Plot the ellipsoidal set 
	(You can use the given \texttt{Ellipsoid} class we provide,
	together with the function \texttt{visualization.plot\_ellipsoid} for this)
	together with the polyhedral set $\{ x \in \R^n \mid x \in X,\; Kx \in U \}$.
	Is the obtained ellipsoidal set a valid terminal set for the MPC problem?
\end{assignment}


Alternatively, we can more directly encode the requirements for the 
invariant set and solve a convex optimization problem 
to find it. 

Let $E = \{ x \in \R^n \mid x^\top P x \leq 1 \}$ denote our candidate set, where 
now $P$ is the positive definite shape matrix. 
Let $K \in \R^{m \times n}$ furthermore be a candidate state feedback gain.
Our goal is to determine 
$P$ and $K$ to obtain the ``largest'' possible positive invariant set for 
$x_{t+1} = A x_t + B u_t$ under the policy $u_t = K x_t$.


\begin{assignment}
	Formulate a constraint on $P$ and $K$ that guarantees that 
	\[ 
		x^\top P x \leq 1 \implies x^\top(A + BK)^\top P (A + BK)x \leq 1  \quad \forall x \in \R
	\]
\end{assignment}



\begin{assignment}\label{sess3:c1}
	Show that the previous constraint can be written as the linear matrix inequality (LMI)
	\[ 
		\begin{bmatrix}
			S & (AS + BF)^\top \\ 
			AS + BF & S
		\end{bmatrix} \geq 0
	\]
	\textbf{Hint.} Doing this involves the following steps. 
	\begin{enumerate}
		\item multiply the inequality you obtained from the left and the right by $P^{-1}$
		\item Introduce the change of variables
			\begin{itemize}
			\item $S=P^{-1}$
			\item $F=KS$
			\end{itemize}
		\item Apply the \href{https://inst.eecs.berkeley.edu/~ee127/sp21/livebook/thm_schur_compl.html}{Schur complement lemma}.
	\end{enumerate}
\end{assignment}



\begin{assignment}\label{sess3:c2}
	Recall from the lectures that 
	\[ 
		E \subseteq \{x \in \R^n \mid Hx \leq g \} \iff \sigma_{E}(H_{i}) \leq g_i, \,\forall i = 1, \dots, p,
	\]
	where $\sigma_E$ denotes the support function of the ellipsoid $E$ and $H_i$ the $i$th row of $H$. 
	Use this fact to show that all states in our candidate invariant set $E$ satisfy the state constraints if and only if 
	\[ 
		H_{x,i}^\top S H_{x,i} \leq h_{x,i}^2, \quad i = 1, \dots, m_x,
	\]
	with $H_{x,i}$ the $i$th row of $H_x$ and $h_{x,i}$ the $i$th coordinate of $h_x$ (see \cref{sess3:assign-lqr})
	and $S = P^{-1}$ as before.

	\textbf{Hint.} An expression for the support function of an Ellipsoid is given in the 
	slides. (It's also a useful exercise to derive it yourself from the definition, but this is not part of the assignment) 
\end{assignment}


\begin{assignment}\label{sess3:c3}
	Similarly, show that $u = Kx$ satisfies the input constraints for all $x \in E$, 
	if and only if 
	\[ 
		h_{u,i}^2 - H_{u,i}^\top F P F^\top H_{u,i} \geq 0, \quad \forall i = 1, \dots, m_{u}.
	\]
	Use the Schur complement lemma to write this constraint as an LMI in $F$ and $S$.
\end{assignment}

\begin{assignment}
	Since the volume of the ellipsoid is proportional to $\log \det P^{-1}$, we can now 
	compute the largest (in terms of volume) invariant set by maximizing $\log \det S$ subject 
	to the constraints in \cref{sess3:c1,sess3:c2,sess3:c3}. 
	
	Implement this problem using \texttt{cvxpy} and plot the resulting ellipsoid (using the given utility code as before) together with the new polyhedral set $\{ x \in \R^n \mid x \in X,\; FS^{-1}x \in U \}$.
\end{assignment}




\newpage
\section{Nonlinear MPC}

We revisit the autonomous parking task but in a slightly more challenging situation. 
Suppose that there is a vehicle in the adjacent parking spot. 

\begin{figure}[ht!]
    \centering 
    \begin{tikzpicture}
        \tikzset{point/.style={circle, fill, inner sep=1pt}}
        \newlength{\pwid}
        \setlength{\pwid}{1cm}
        \newlength{\phei}
        \setlength{\phei}{0.48cm}
        \newlength{\cw}  % Car width 
        \newlength{\ch}  % Car height 
        \setlength{\cw}{0.8cm}
        \setlength{\ch}{0.4cm}
        
        \fill[gray!80!cyan] (-4\pwid, 1.5\phei) rectangle (4\pwid, -3\phei);
        \fill[black!70!cyan] (-4\pwid, 0.5\phei) rectangle (4\pwid, -3\phei); 
        \foreach\i in {-2,-1,...,2}{
            \begin{scope}[xshift=\i\pwid]
            \draw[very thick, white] (-0.5\pwid, -0.5\phei) rectangle (0.5\pwid, 0.5\phei);
            \end{scope}
        }
        \colorlet{carcol}{blue!50!cyan}
		\colorlet{obstaclecol}{red!80!black}
        \node[point, label=left:{\color{cyan}\textbf{Goal}}, color=cyan] {};
        \fill[carcol, rounded corners] (1.3\pwid-0.5\cw, -1.2\phei-0.5\ch) rectangle ++(\cw,\ch) coordinate[midway] (carcenter);
        \draw[->, >=stealth, thick, carcol] ($(carcenter)-(0.5\cw,0)$) to[in=0,out=180] (0,0); 
        \node[text=white] at (carcenter){car};
		
		\fill[obstaclecol, rounded corners] (1\pwid-0.5\cw, -0.5\ch) rectangle ++(\cw,\ch) coordinate[midway] (obscenter);
		\node[text=white] at (obscenter){obs};

    \end{tikzpicture}
    \caption{Autonomous parking task with obstacle}
    \label{fig:task}
\end{figure}

Naturally, the vehicle can in no circumstance be allowed to collide with the stationary obstacle. 
The goal of this assignment is to modify the MPC formulation from the exercise session to include collision avoidance constraints. 

One way of formulating the collision avoidance constraint is to cover each vehicle with a single row of circles as illustrated in  
\cref{fig:circles}. 
Here, $d$ denotes the horizontal distance between the center of each 
circle and its intersection with the rectangle, $r$ denotes the 
radius of the circles, $l$ is the length of the vehicle and $w$ is the width of the vehicle.

\begin{figure}[ht!]
	\centering
	\foreach \i in {2,3,5}{
	\begin{minipage}{0.3\textwidth}
	   \includegraphics[width=\textwidth]{figures/covering_circles\i.pdf}
	\end{minipage}
	}
	\caption{Vehicle covering with 2, 3 and 5 circles respectively.}
	\label{fig:circles}
\end{figure}


\newcommand{\nc}{n_{\mathrm{c}}}
\begin{assignment}
	Let $\nc$ denote the number of circles used to cover the vehicle. 
	Based on the figure, derive an expression 
	for the \textbf{centers} $c_i \in \R^2$, $i = 0, \dots, \nc-1$ 
	and the radius $r \in \R_+$ of the circles
	as a function of $l$, $w$ and $\nc$. 
	Assume that the origin lies in the center of the vehicle (i.e., the rectangle).
	
	Consider a vehicle of $l=4$ and $w=2$, and take $\nc=3$. 
	To verify your results, use \texttt{Circle} and \texttt{Rectangle} from \texttt{matplotlib.patches} 
	to plot it for this example.

	\textbf{Hint:} This task involves only basic geometry.
\end{assignment}
\begin{solutionbox}
\begin{itemize}
	\item \textbf{Radius Calculation:} Given that the first circle is from a distance $d$ from the edge, radius $r$ can be calculated as the smallest circle that contains the edge. Applying the Pythagoras theorem 
	$$
		r = \sqrt{\frac{w^2}{4}+d^2}
	$$
	\item \textbf{Edge Distance $d$ Calculation:} The entire length $l$ is divided into $n_c$ segments of length $2d$. Therefore 
	$$
		d = \frac{l}{2n_c}
	$$
	\item \textbf{Center Calculation:} The centers are placed on the x axis of the origin at the vehicle center. The coordinates of the intersection of left edge and the x axis are $(-l/2,0)$. The centers are placed at odd multiples of $d$ from this point. Therefore 
	$$
		c_i = \left(-\frac{l}{2} + (2i+1)d, 0\right)
	$$
\end{itemize}

Using the above calculations, a rectangle with $l=4$, $w=2$ and $n_c=3$ is shown below. 
\begin{center}
	\includegraphics[width=0.7\textwidth]{../figs/4.1.pdf}
	\captionsetup{hypcap=false}
	\captionof{figure}{Application of the derived formulas}
	\label{fig:circles}
\end{center}
\end{solutionbox}

\begin{assignment}
	Given that the current vehicle state is $x = (p_x, p_y, \psi, v)$, 
	express the center $\bar{c}$ of a circle in global coordinates, given that its local coordinates 
	(aligned with the vehicle, as in the previous exercise) are given by $c$.

	For a vehicle of length $l = 4$, width $w = 2$, with its center at $p = (2,2)$
	and heading angle $\psi = \tfrac{\pi}{4}$, use your result (combined with the previous assignment) to plot the 
	covering circles on this vehicle for $\nc = 3$.

	\textbf{Hint:} You can write your result in terms of the rotation matrix $R(\psi)$ defined by 
	the heading angle $\psi$. There is no need to work out everything into individual components.
\end{assignment}
\begin{solutionbox}
The rotation matrix to rotate a point on 2D plane counter-clockwise by $\psi$ radians is given by 
$$
R(\psi) = \begin{bmatrix}
    \cos \psi & -\sin \psi \\
    \sin \psi & \cos \psi
\end{bmatrix}
$$
The centers of the circles need to undergo a rotation and a shift (in that order) to go from local coordinates to global coordinates. The centers in global coordinates are given by 
$$
	\bar{c} = R(\psi)c + p 
$$
Where $p = (p_x, p_y)$ is the shift vector which points to the center of the car. Figure~\ref{fig:4.2} shows the result of this rotating and shifting.
\begin{center}
	\includegraphics[width=0.5\linewidth]{../figs/4.2.pdf}
	\captionsetup{hypcap=false}
	\captionof{figure}{The centers shifted and rotated}
	\label{fig:4.2}
\end{center}
\end{solutionbox}

\begin{assignment}
	Given that the controlled vehicle is covered by circles with 
	centers $\bar{c}_i$ $i = 0, \dots, \nc-1$ (expressed in global coordinates) and
	radius $r$, and similarly the obstacle vehicle is covered by circles 
	with centers $\bar{c}_i'$ and radius $r'$. 
	Formulate a set of \textit{smooth} constraints 
	\[ 
		g(\bar{c}_i, \bar{c}_j) \leq 0
	\]
	on $\bar{c}_i$ and $\bar{c}_j'$, $i,j \in 0, \dots, \nc-1$.
	which -- when satisfied -- guarantees that the intersection between 
	the two vehicle rectangles is empty.

	Additionally, show whether this set of constraints is convex or not.

	\textbf{Hint:} Squaring can get rid of isolated points of non-smoothness.
\end{assignment}
\begin{solutionbox}
No collision translates to no overlap between circles. So, the condition can be written as 
$$
	\|\bar{c}_i - \bar{c}_j'\|_2 \ge r-r'
$$
The $\ell_2$ norm is non-smooth at the origin. Squaring both sides 
$$
	\|\bar{c}_i - \bar{c}_j'\|_2^2 -(r-r')^2 \ge 0
$$
Rearranging to get the desired form 
$$
	g(\bar{c}_i,\bar{c}_j') = (r-r')^2 -\|\bar{c}_i - \bar{c}_j'\|_2^2 \le 0
$$
Since the obstacles do not move, there centers are constant. Visually a negative sign on the quadratic function means it is not convex. However to confirm, the Hessian w.r.t $\bar{c}_i$ is 
$$
	\nabla^2 g = \begin{bmatrix}
    -2 & 0 \\
    0 & -2
\end{bmatrix}
$$
Which has negative eigenvalues thus the constraint is not convex.
\end{solutionbox}

\begin{assignment}
	Implement the constraint you derived into your MPC controller formulation.
	That is, enforce that 
	\[
		g(\bar{c}_i(x_t), \bar{c}_j') \leq 0, \quad \forall i,j \in \{0, \dots, \nc-1\}, \forall t \in 1, \dots, N. 
	\]
	where $\bar{c}_{i}(x_t)$ is the center (in global coordinates) of the $i$'th circle on the 
	controlled vehicle expressed as a function of its state at time step $t$,
	$\bar{c}_j'$ is the center (in global coordinates) of the $j$'th circle 
	on the obstacle vehicle and $g$ is the function you derived in the previous 
	exercise.

	Using the following settings, Simulate your MPC controller for 100 time steps in closed loop.
	You can use the MPC model dynamics for the simulation (no model mismatch):
	
	\begin{center}
	\begin{tabular}{cc}
		\toprule
		$x_0$ & $(0.3, -0.1, 0, 0)$ \\
		$N$   & 30 \\ 
		$\Ts$ & 0.08 \\ 
		Obstacle pos. & $(0.25, 0)$ (heading 0)\\
		\bottomrule
	\end{tabular}
	\end{center}
	
	Use \texttt{plot\_state\_trajectory} from \texttt{given.plotting} to 
	visualize the state trajectory, including the obstacle (simply pass the function a list with only one state, since it is stationary).
	Is the trajectory collision-free? 
	Does the car converge to a point that is entirely within the parking spot
	\footnote{
	defined in the code as a rectangle with dimensions \texttt{PARK\_DIMS=}$(0.25, 0.12)$
	}?

	Optionally, you can also generate an animation using \texttt{given.animation}, but this is 
	not a deliverable.
	(see the solution of the exercise session for some example code. You can use the argument \texttt{obstacle\_positions} to visualize the obstacle.)

\end{assignment}
\begin{solutionbox}
\begin{center}
	\includegraphics[width=0.5\linewidth]{../figs/4.4.pdf}
	\captionsetup{hypcap=false}
	\captionof{figure}{Obstacle avoidance with the constraint}
	\label{fig:4.4}
\end{center}
The derived constraint was implemented in the MPC controller. Weights of the controller were $Q=\mathrm{diag}(1,3,0.1,0.01),~Q_N=5Q,~R=\mathrm{diag}(1,0.01)$, Figure~\ref{fig:4.4} shows that without the constraint, the rectangles overlap meaning a collision occurs. With the constraint the rectangles do not overlap and the collision is avoided. However the car does not converge to a point that is within the parking spot. It shows a little offset in y-axis.
\end{solutionbox}


\begin{assignment}
	Play around with the tuning of $Q$, $R$, $N$ or other controller parameters (perhaps even $\nc$, feel free to get creative)
	to obtain a controller which can (without collision) park the vehicle such that it is fully enclosed in the 
	parking spot. Briefly describe your reasoning while tuning, 
	report the final parameters that you changed from the provided defaults
	and illustrate the final result with a plot of the trajectory.
\end{assignment}

\begin{solutionbox}
Figure~\ref{fig:4.4} shows that there is an offset in $y$ and the car is not parked fully horizontal ($\psi \ne 0$). Increasing the weight of $y$ in $Q$ ($Q=\mathrm{diag}(1,\mathbf{15},0.1,0.01)$) makes the controller more aggressive, reducing the offset by increasing the velocity and angles in the trajectory as shown in Figure~\ref{fig:4.5-1}. 
\begin{center}
	\includegraphics[width=0.5\linewidth]{../figs/4.5-2-iter1.pdf}
	\captionsetup{hypcap=false}
	\captionof{figure}{Improvement with $Q=\mathrm{diag}(1,\mathbf{15},0.1,0.01)$.  (Baseline with original weights)}
	\label{fig:4.5-1}
\end{center}

However the parking angle was found to be a little off still. Further improvement was found by realizing that the offset and angle had to be zero only at the end of the trajectory. Therefore this time, $Q$ was kept the original and $Q_f$ was changed to $Q_f=\mathrm{diag}(5,\mathbf{50},\mathbf{50},5)Q$. This creates a cost function that penalizes last states much more aggressively thus forcing the controller to make a trajectory that ends closer to the origin, thus removing the offsets. Figure~\ref{fig:4.5-2} shows that this controller is not as aggressive during the maneuver and still stops at the center. This controller's performance was deemed acceptable and iterations were stopped. Figure~\ref{fig:4.5-3} shows the trajectory of the controller with obstacle showing successful avoidance.

\begin{center}
	\includegraphics[width=0.5\linewidth]{../figs/4.5-2.pdf}
	\captionsetup{hypcap=false}
	\captionof{figure}{Improvement with $Q_f=\mathrm{diag}(5,\mathbf{50},\mathbf{50},5)Q$. (Baseline with original weights)}
	\label{fig:4.5-2}
\end{center}
\begin{center}
	\includegraphics[width=0.5\linewidth]{../figs/4.5-1.pdf}
	\captionsetup{hypcap=false}
	\captionof{figure}{Trajectory of improved controller}
	\label{fig:4.5-3}
\end{center}
\end{solutionbox}

\begin{assignment}
	Measure your solver time. A quick and easy way to do this is to invoke \texttt{perf\_counter} 
	from the \texttt{time} module before and after your solver call, within the \texttt{\_\_call\_\_} 
	method of your controller. In general, if a solver returns its own time, its usually better to use this instead of measuring the time yourself, in order 
	not to account for overhead in the modeling language. For this assignment, however, you can just use your own timing.
	You can log the solver time by 
	creating a log class 
	\begin{lstlisting}[style=python]
from dataclasses import dataclass
from rcracers.simulator.core import BaseControllerLog, list_field
@dataclass
class ControllerLog(BaseControllerLog): 
    solver_time: list = list_field()
	\end{lstlisting}
	and passing it as \texttt{log} to the \texttt{simulate} method:
	\begin{lstlisting}[style=python]
from rcracers.simulator import simulate
log = ControllerLog()   # Initialize an empty log 
x = simulate(..., log=log) # Simulate 
print(log.solver_time)  # Now the solver times have been written 
	\end{lstlisting}
	Within your solver call, you can then log it like this:
	\begin{lstlisting}[style=python]
from time import perf_counter
def __call__(self, y, log) -> np.ndarray:
	start = perf_counter()
	solution = self.solve(y)
	stop = perf_counter()
	u = self.reshape_input(solution)
	log("solver_time", stop-start)
	return u[0]
	\end{lstlisting}
	Visualize the resulting solver time. Is your MPC controller real-time capable? How did you verify this? If it isn't, finetune your controller to 
	obtain one that is real-time capable and still successfully parks into the parking area.
	Report your final tuning (any value that you changed from the provided defaults)
	and show the timings and state trajectory of the final controller.
\end{assignment}

\begin{solutionbox}
The solver time was logged using a global variable and \texttt{perf\_counter}. Figure~\ref{fig:4.6-1} shows the time per iteration in blue. The controller violates the real-time constraint (time per iteration < $T_s=0.08$s) before 40 iterations. To fix this, the horizon was reduced from $N=30$ to $N=25$ without sacrificing performance (Figure~\ref{fig:4.6-2}). The updated controller now satisfies the real-time constraint.
\begin{center}
	\includegraphics[width=0.5\linewidth]{../figs/4.6-time.pdf}
	\captionsetup{hypcap=false}
	\captionof{figure}{Time taken per iteration}
	\label{fig:4.6-1}
\end{center}
\begin{center}
	\includegraphics[width=0.5\linewidth]{../figs/4.6-Fast.pdf}
	\captionsetup{hypcap=false}
	\captionof{figure}{Comparison of $N=30$ (Tuned) and $N=25$ (Fast)}
	\label{fig:4.6-2}
\end{center}
\end{solutionbox}

\newpage
\section{State estimation}
The goal of this assignment is to further improve the MHE you developed in the 
associated exercise session. Specifically right now we only use the data 
provided within the horizon of the MHE optimization problem. Instead 
we would like to use past information as well, which we can do using priors. 
\begin{assignment}
 	We will implement a prior update. Since you already 
    have the EKF iterates available, these can be used to add the \emph{filtering prior update}
    as described in the slides:
    \begin{equation*}
        \Gamma_{T-N}(z) = \frac{1}{2} \nrm{z - \hat{x}_{T-N}}_{(P^-_{T-N})^{-1}}.
    \end{equation*}
    \begin{enumerate}
        \item Note that the \texttt{prior} can already be passed to the provided \texttt{build\_mhe} method:
        \begin{lstlisting}[style=python]
fs, hs = get_system_equations(symbolic=True, noise=True)
loss = lambda w, v: w.T @ w + v.T @ v
solver = build_mhe(loss, f, h, 10, lbx=0.0, ubx=10.0, use_prior=True)

# you can solve the optimization problem as follows:
x, w = solver(P=np.eye(3), x0=np.zeros(3), y=np.zeros((10, 1)))
\end{lstlisting}
        
        \item Alter your \texttt{MHE} class to use \texttt{EKF} internally. Initialize your 
        \texttt{EKF} with the same values as during the exercise session. 
        Keep in mind that you should produce $\hat{x}_{T-N}$ using only measurements 
        available before time step $T-N$ and the same is true for $P^-_{T-N}$. 
        How many past estimates $\hat{x}_{T-N}$ and $P^-_{T-N}$ should you store 
        internally?

        \item Verify, both for longer horizons ($N = 25$) and shorted ($N=10$) ones
        that the filtering prior improves the behavior. Plot the estimated 
		trajectories.
        
        \item Does clipping the state estimates in the \emph{EKF} aid the 
        performance? Plot the result.
    \end{enumerate}
    \solution{See \texttt{MHE} in \texttt{session4\_sol.py}.} 
\end{assignment}



\newpage 
\section{Optimization}

The goal of this assignment is to get familiar with methods for solving nonlinear MPC problems. 
Due to the nonlinearity of the dynamics, the OCP
will be nonconvex and therefore, the methods from during the session will no longer be applicable. 

The given code (\texttt{problem.py}), 
defines a few test problems and some data-structures that 
you can use to build your nonlinear solver. Have a brief 
look at this file, and read the comments therein
to get acquainted with the provided ingredients.
You will not be required to make any changes 
in this file.  

A scaffolding for your own implementation is given 
in \texttt{template.py}. Throughout this 
assignment, you will fill in the blanks in this file, 
to finally obtain a solver for nonlinear optimal control problems.

\subsection{Building the solver}
We will build a Newton-Lagrange method 
for multiple shooting (i.e., simultaneous approach).

\begin{assignment}
	Implement the Newton-Lagrange method (SQP) by 
	completing the auxiliary functions used by \texttt{newton\_lagrange} in 
	the provided template. Particularly, 
	the functions \texttt{lqr\_factor\_step}, \texttt{lqr\_solve\_step}
	and \texttt{update\_iterate} need to be implemented. The former two functions should implement 
	Algorithms 2 and 3 in the related lecture slides. 
	In \texttt{update\_iterate}, you can for now assume that the option \texttt{linesearch} is \texttt{False}.

	Run the function \texttt{test\_linear\_system} and present the output.
	This function calls your SQP solver on a problem involving 
	a linear system. Is the output what you expect? Why?
\end{assignment}
\begin{lstlisting}[style=python]
	<Paste the output of the program here.>
\end{lstlisting}


\subsection{Nonlinear test case}
Now that you have tested your implementation on a linear system,
we will move on to a nonlinear example.

Consider the continuous time dynamics 
\[
\begin{aligned}
  \dot{x}_1 &=  10(x_2 - x_1) \\
  \dot{x}_2 &= x_1(u - x_3) - x_2 \\
  \dot{x}_3 &= x_1x_2 - 3x_3 
\end{aligned}
.\] 
which are discretized using the foward Euler scheme. 
This system is already implemented in \texttt{problem.py} under \texttt{ToyDynamics}. 
The problem that you can pass to your SQP solver is described by \texttt{ToyProblem}.

\begin{assignment} \label{assgn:62}
	Construct an initial guess of all zeros for the inputs, the states and the costates.
	However, for the states, keep in mind that the first entry must be the provided initial 
	state, i.e., \texttt{problem.x0}. Run your solver with this 
	initial state. Give the cost and constraint violation of the last iterate
	(printed automatically using the \texttt{Logger} class in \texttt{given.problem}). 
	Use the provided \texttt{animate\_iterates} function to animate the states and inputs over the iterates and to export a 
	figure of the final solution. Add this plot in your report. Does your solution look plausible?
\end{assignment}


\begin{assignment} \label{assgn:simulate-init}
   Simulate the system and use this as an initial guess.

   You may find that the solver now fails to converge. 
   Why do you think this happens? 
   
   \textbf{Hint.} Plot the state trajectory you used as an initial guess. 
   Does it look like the solution you just obtained in the previous exercise? 
   Why is this important?
\end{assignment}



\subsection{Adding Line Search}

\begin{assignment}
   Implement line search and the experiment of \cref{assgn:simulate-init}. 
   Use 
	\[ 
		\phi(z) = J_N(z) + c \nrm{h(z)}_1 
	\]
	as a merit function (see \texttt{problem.build\_cost\_and\_constraint}). 

	\textbf{Hint.} Make sure to set \texttt{linesearch=True} in the \texttt{cfg} argument of the solver, 
	which is expected to be an instance of \texttt{NewtonLagrangeCfg}.
	
   Now does it converge? Give the output of the method at the final iterate and use this 
   to argue that your method indeed converged to something meaningful. 
   Do you notice any difference with respect to the solution in \cref{assgn:62}? 
   How do you explain this?
\end{assignment}




\begin{assignment}
   Run it on the parking example. Use initial condition all zeros (except $x_0 = $\texttt{problem.x0}).
   
	Does it converge? Why? 
	
	\textbf{Hint. } During the Newton-Lagrange iterations, check whether the Hessian of the QP cost is positive definite.
\end{assignment}



\subsection{Adding Regularization}

\begin{assignment}
	Implement regularization in the function \texttt{regularize}. This method should 
	check whether the QP is convex. 
	If not, it should add $\lambda I$ to the Hessian $\overline{Q}$ of the cost function, where $\lambda$ is 
	(approximately) the smallest constant such that $\overline{Q} + \lambda I$ is positive definite.
	To do so set $\lambda = 10^{-6}$ and double it every time the result is not positive definite. 
	
	With this modification, run the method again on the Parking problem. Does it converge? 
	\textbf{Hint.}  Make sure to set \texttt{cfg.regularize} to \texttt{True}!
\end{assignment}


 


\end{document}

